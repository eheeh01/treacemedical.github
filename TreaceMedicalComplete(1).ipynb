{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31eaa065-9216-4dd2-8b50-7874bae75631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harrison ehee\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "zipcode|MIS|Lap|Both|MIS_only|Lap_only\n",
      "10022|MIS=7|Lap=21|Both=4|MIS_only=3|Lap_only=17\n",
      "10024|MIS=6|Lap=21|Both=4|MIS_only=2|Lap_only=17\n",
      "11215|MIS=11|Lap=19|Both=4|MIS_only=7|Lap_only=15\n",
      "07078|MIS=11|Lap=21|Both=4|MIS_only=7|Lap_only=17\n",
      "07302|MIS=11|Lap=21|Both=5|MIS_only=6|Lap_only=16\n",
      "08540|MIS=5|Lap=5|Both=0|MIS_only=5|Lap_only=5\n",
      "19103|MIS=3|Lap=10|Both=2|MIS_only=1|Lap_only=8\n",
      "20007|MIS=4|Lap=7|Both=1|MIS_only=3|Lap_only=6\n",
      "20815|MIS=4|Lap=7|Both=1|MIS_only=3|Lap_only=6\n",
      "02116|MIS=0|Lap=3|Both=0|MIS_only=0|Lap_only=3\n",
      "02445|MIS=0|Lap=5|Both=0|MIS_only=0|Lap_only=5\n",
      "06830|MIS=3|Lap=8|Both=1|MIS_only=2|Lap_only=7\n",
      "15213|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "23226|MIS=0|Lap=0|Both=0|MIS_only=0|Lap_only=0\n",
      "28207|MIS=0|Lap=3|Both=0|MIS_only=0|Lap_only=3\n",
      "27608|MIS=0|Lap=4|Both=0|MIS_only=0|Lap_only=4\n",
      "30309|MIS=7|Lap=8|Both=4|MIS_only=3|Lap_only=4\n",
      "33146|MIS=10|Lap=6|Both=3|MIS_only=7|Lap_only=3\n",
      "33139|MIS=10|Lap=6|Both=3|MIS_only=7|Lap_only=3\n",
      "33480|MIS=4|Lap=4|Both=2|MIS_only=2|Lap_only=2\n",
      "33308|MIS=9|Lap=7|Both=4|MIS_only=5|Lap_only=3\n",
      "33606|MIS=2|Lap=3|Both=0|MIS_only=2|Lap_only=3\n",
      "32207|MIS=3|Lap=7|Both=3|MIS_only=0|Lap_only=4\n",
      "37215|MIS=6|Lap=4|Both=2|MIS_only=4|Lap_only=2\n",
      "38120|MIS=0|Lap=0|Both=0|MIS_only=0|Lap_only=0\n",
      "70808|MIS=1|Lap=1|Both=1|MIS_only=0|Lap_only=0\n",
      "70115|MIS=0|Lap=6|Both=0|MIS_only=0|Lap_only=6\n",
      "60614|MIS=8|Lap=12|Both=4|MIS_only=4|Lap_only=8\n",
      "60611|MIS=7|Lap=12|Both=4|MIS_only=3|Lap_only=8\n",
      "60093|MIS=9|Lap=13|Both=5|MIS_only=4|Lap_only=8\n",
      "48236|MIS=5|Lap=3|Both=0|MIS_only=5|Lap_only=3\n",
      "48301|MIS=6|Lap=6|Both=1|MIS_only=5|Lap_only=5\n",
      "55408|MIS=0|Lap=3|Both=0|MIS_only=0|Lap_only=3\n",
      "55424|MIS=0|Lap=3|Both=0|MIS_only=0|Lap_only=3\n",
      "53217|MIS=0|Lap=0|Both=0|MIS_only=0|Lap_only=0\n",
      "64113|MIS=1|Lap=4|Both=1|MIS_only=0|Lap_only=3\n",
      "66211|MIS=1|Lap=4|Both=1|MIS_only=0|Lap_only=3\n",
      "45429|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "44124|MIS=2|Lap=2|Both=1|MIS_only=1|Lap_only=1\n",
      "46220|MIS=2|Lap=3|Both=0|MIS_only=2|Lap_only=3\n",
      "77027|MIS=3|Lap=11|Both=3|MIS_only=0|Lap_only=8\n",
      "77005|MIS=2|Lap=10|Both=2|MIS_only=0|Lap_only=8\n",
      "75225|MIS=6|Lap=24|Both=6|MIS_only=0|Lap_only=18\n",
      "75093|MIS=5|Lap=22|Both=5|MIS_only=0|Lap_only=17\n",
      "78746|MIS=0|Lap=5|Both=0|MIS_only=0|Lap_only=5\n",
      "78209|MIS=5|Lap=13|Both=5|MIS_only=0|Lap_only=8\n",
      "73116|MIS=1|Lap=6|Both=1|MIS_only=0|Lap_only=5\n",
      "73120|MIS=1|Lap=6|Both=1|MIS_only=0|Lap_only=5\n",
      "72205|MIS=0|Lap=0|Both=0|MIS_only=0|Lap_only=0\n",
      "35801|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "35223|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "80206|MIS=7|Lap=15|Both=7|MIS_only=0|Lap_only=8\n",
      "80209|MIS=7|Lap=15|Both=7|MIS_only=0|Lap_only=8\n",
      "84105|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "85718|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "85016|MIS=2|Lap=10|Both=2|MIS_only=0|Lap_only=8\n",
      "89509|MIS=1|Lap=1|Both=1|MIS_only=0|Lap_only=0\n",
      "59715|MIS=0|Lap=0|Both=0|MIS_only=0|Lap_only=0\n",
      "83702|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "90049|MIS=3|Lap=4|Both=0|MIS_only=3|Lap_only=4\n",
      "90210|MIS=4|Lap=6|Both=1|MIS_only=3|Lap_only=5\n",
      "90402|MIS=3|Lap=4|Both=0|MIS_only=3|Lap_only=4\n",
      "92130|MIS=1|Lap=2|Both=1|MIS_only=0|Lap_only=1\n",
      "92660|MIS=1|Lap=4|Both=1|MIS_only=0|Lap_only=3\n",
      "94123|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "94109|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "94301|MIS=0|Lap=3|Both=0|MIS_only=0|Lap_only=3\n",
      "94596|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "97210|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "98109|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "98105|MIS=0|Lap=2|Both=0|MIS_only=0|Lap_only=2\n",
      "96816|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "96734|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "99503|MIS=0|Lap=0|Both=0|MIS_only=0|Lap_only=0\n",
      "96701|MIS=0|Lap=1|Both=0|MIS_only=0|Lap_only=1\n",
      "Saved: C:\\Users\\Harrison Ehee\\Downloads\\Python Projects\\treace_zipcode_surgeon_counts_20251228_190936.xlsx\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pandas openpyxl\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#token-based name extraction (stops at non-name words like \"is/has..etc\", blocks places like \"college\")\n",
    "NAME_TOKEN = re.compile(r\"^(?:[A-Z]\\.|[A-Z][A-Za-z\\-\\']+\\.?)$\")\n",
    "\n",
    "#Lists of words that serve as warning signs. Ensure numbers aren't inflated and no false positives\n",
    "STOP_WORDS_LOWER = {\n",
    "    \"is\", \"was\", \"were\", \"are\", \"has\", \"have\", \"had\",\n",
    "    \"offers\", \"offer\", \"specializes\", \"specializes\", \"completed\",\n",
    "    \"interned\", \"trained\", \"certified\", \"currently\", \"often\", \"also\",\n",
    "    \"a\", \"an\", \"the\", \"and\", \"of\", \"in\", \"at\", \"for\", \"with\", \"to\", \"from\"\n",
    "}\n",
    "BAD_LASTWORDS = {  #things that are not a last name\n",
    "    \"College\", \"University\", \"Center\", \"Hospital\", \"System\", \"Clinic\", \"Medical\",\n",
    "    \"Health\", \"Services\", \"Associates\", \"Group\", \"Institute\", \"Practice\"\n",
    "}\n",
    "BAD_NAME_TERMS = {\n",
    "    \"college\", \"school\", \"university\", \"medical\", \"medicine\",\n",
    "    \"hospital\", \"center\", \"centre\", \"clinic\", \"institute\",\n",
    "    \"foundation\", \"program\", \"department\", \"services\",\n",
    "    \"health\", \"system\", \"group\", \"associates\"\n",
    "}\n",
    "\n",
    "def get_names(text):\n",
    "    names = []\n",
    "    #match \"Dr.\" or \"Dr\" \n",
    "    for m in re.finditer(r\"\\bDr\\.?\\s+\", text):\n",
    "        i = m.end()\n",
    "        #grab a short window after \"Dr.\" and tokenize it\n",
    "        window = text[i:i+80]\n",
    "        tokens = re.findall(r\"[A-Za-z\\-\\']+\\.?\", window)\n",
    "\n",
    "        collected = []\n",
    "        for t in tokens:\n",
    "            #stop if hit normal sentence words\n",
    "            if t.lower().strip(\".\") in STOP_WORDS_LOWER:\n",
    "                break\n",
    "            #keep only name-like tokens (capitalized words/initials)\n",
    "            if not NAME_TOKEN.match(t):\n",
    "                break\n",
    "            collected.append(t.strip())\n",
    "            if len(collected) >= 5:\n",
    "                break\n",
    "        #require at least first + last\n",
    "        if len(collected) >= 2:\n",
    "            last = collected[-1].strip(\".\")\n",
    "            if last in BAD_LASTWORDS:\n",
    "                continue\n",
    "            full = \"Dr. \" + \" \".join(collected).replace(\"  \", \" \").strip()\n",
    "            #reject institutions disguised as doctors (false positive)\n",
    "            last_word = full.split()[-1].lower().strip(\".,\")\n",
    "            if last_word in BAD_NAME_TERMS:\n",
    "                continue\n",
    "            names.append(full)\n",
    "    #remove duplicates while keeping order\n",
    "    names = list(dict.fromkeys(names))\n",
    "    return names\n",
    "\n",
    "#particles that can be part of a compound last name\n",
    "LASTNAME_PARTICLES = {\n",
    "    \"da\",\"de\",\"del\",\"della\",\"der\",\"di\",\"la\",\"le\",\"van\",\"von\",\"st\",\"st.\"\n",
    "}\n",
    "#helps prevent duplicate names from being counted towards number of surgeons in that procedure (keeps numbers from being inflated)\n",
    "def key(dr_name: str):\n",
    "    # remove \"Dr.\" and extra spaces\n",
    "    s = re.sub(r\"^Dr\\.\\s*\", \"\", dr_name).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    #strip common credentials stuck onto the end (keeps names cleaner)\n",
    "    s = re.sub(r\"\\b(MD|DO|DPM|DDS|DMD|PhD|FACS|FACFAS)\\b\\.?\", \"\", s, flags=re.I).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    parts = s.split()\n",
    "    if not parts:\n",
    "        return (\"\", \"\")\n",
    "    #build last name (for compound last names like \"Del Monte\", \"Van Dyke\", etc.)\n",
    "    last = parts[-1].lower()\n",
    "    if len(parts) >= 2 and parts[-2].lower().rstrip(\".\") in LASTNAME_PARTICLES:\n",
    "        last = (parts[-2] + \" \" + parts[-1]).lower()\n",
    "    #if no clear first name leave first_initial blank\n",
    "    first_initial = \"\"\n",
    "    if len(parts) >= 3:\n",
    "        first_initial = parts[0][0].lower()\n",
    "    return (last, first_initial)\n",
    "    \n",
    "def dedupe_by_key(names):\n",
    "    best_by_full = {}\n",
    "    best_by_last = {}\n",
    "    for n in names:\n",
    "        last, fi = key(n)\n",
    "        #if first initial is missing, dedupe by last name only\n",
    "        if fi == \"\":\n",
    "            if last not in best_by_last or len(n) > len(best_by_last[last]):\n",
    "                best_by_last[last] = n\n",
    "            continue\n",
    "        k = (last, fi)\n",
    "        if k not in best_by_full or len(n) > len(best_by_full[k]):\n",
    "            best_by_full[k] = n\n",
    "        if last not in best_by_last or len(n) > len(best_by_last[last]):\n",
    "            best_by_last[last] = n\n",
    "    #if a \"last-only\" entry matches a full entry's last name, keep the better one\n",
    "    out = list(best_by_full.values())\n",
    "    full_lasts = {k[0] for k in best_by_full.keys()}\n",
    "    for last, n in best_by_last.items():\n",
    "        if last not in full_lasts:\n",
    "            out.append(n)\n",
    "    return out\n",
    "\n",
    "zipcodes = pd.read_excel(\"C:/Users/Harrison Ehee/Downloads/Python Projects/zipcodes.xlsx\")\n",
    "zipcodes.head()\n",
    "#request headers\n",
    "headers = {\n",
    "    \"accept\": \"text/x-component\",\n",
    "    \"content-type\": \"text/plain;charset=UTF-8\",\n",
    "    \"origin\": \"https://locator.treace.net\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"next-action\": \"f6fdafddf3397baac6cf9b5e5ca7ee6e2676372b\",\n",
    "}\n",
    "#loop over all zipcodes + write results to excel\n",
    "def fetch_surgeons_for_zip(zip_code, procedure, next_action, radius=25):\n",
    "    #build a referer url \n",
    "    referer_url = f\"https://locator.treace.net/?q={zip_code}&radius={radius}&procedure={quote(procedure)}\"\n",
    "    payload = f'[{{\"query\":\"{zip_code}\",\"radius\":{radius},\"filters\":[],\"procedure\":\"{procedure}\",\"npi\":\"\",\"surgeonName\":\"\"}}]'\n",
    "    \n",
    "    h = headers.copy()\n",
    "    h[\"next-action\"] = next_action\n",
    "    h[\"referer\"] = referer_url\n",
    "\n",
    "    r = requests.post(\"https://locator.treace.net/\", headers=h, data=payload, timeout=20)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    names_raw = get_names(r.text)\n",
    "    names = dedupe_by_key(names_raw)\n",
    "    return names_raw, names\n",
    "\n",
    "RADIUS = 25\n",
    "NEXTACT_MIS = \"f6fdafddf3397baac6cf9b5e5ca7ee6e2676372b\"\n",
    "PROCEDURE_MIS = \"MISSurgeon\"\n",
    "NEXTACT_LAP = \"f6fdafddf3397baac6cf9b5e5ca7ee6e2676372b\"\n",
    "PROCEDURE_LAP = \"Lapiplasty Surgeon\"\n",
    "\n",
    "print(\"zipcode|MIS|Lap|Both|MIS_only|Lap_only\")\n",
    "\n",
    "#loop through every zipcode in your first column\n",
    "rows = [] \n",
    "for i in range(len(zipcodes)):\n",
    "    zip_code = str(zipcodes.iloc[i, 0]).split(\".\")[0].zfill(5)\n",
    "    try:\n",
    "        mis_raw, mis = fetch_surgeons_for_zip(zip_code, PROCEDURE_MIS, NEXTACT_MIS, radius=RADIUS)\n",
    "        lap_raw, lap = fetch_surgeons_for_zip(zip_code, PROCEDURE_LAP, NEXTACT_LAP, radius=RADIUS)\n",
    "        mis_set = set(mis)\n",
    "        lap_set = set(lap)\n",
    "        both = (mis_set & lap_set)\n",
    "        mis_only = (mis_set - lap_set)\n",
    "        lap_only = (lap_set - mis_set)\n",
    "        rows.append({\n",
    "            \"Zipcode\": zip_code,\n",
    "            \"MIS\": len(mis_set),\n",
    "            \"Lapiplasty\": len(lap_set),\n",
    "            \"Both\": len(both),\n",
    "            \"MIS only\": len(mis_only),\n",
    "            \"Lapiplasty only\": len(lap_only),\n",
    "        })\n",
    "        print(f\"{zip_code}|MIS={len(mis_set)}|Lap={len(lap_set)}|Both={len(both)}|MIS_only={len(mis_only)}|Lap_only={len(lap_only)}\")\n",
    "        time.sleep(0.4)\n",
    "    except Exception as e:\n",
    "        #still keep the row so output stays aligned to the input file order\n",
    "        rows.append({\n",
    "            \"Zipcode\": zip_code,\n",
    "            \"MIS\": None,\n",
    "            \"Lapiplasty\": None,\n",
    "            \"Both\": None,\n",
    "            \"MIS only\": None,\n",
    "            \"Lapiplasty only\": None,\n",
    "            \"Error\": str(e),\n",
    "        })\n",
    "        print(f\"{zip_code}: ERROR -> {e}\")\n",
    "\n",
    "out_df = pd.DataFrame(rows)\n",
    "#make a new file (with timestamp) each time code is run without overwriting previous file\n",
    "base_dir = r\"C:\\Users\\Harrison Ehee\\Downloads\\Python Projects\"\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = os.path.join(\n",
    "    base_dir,\n",
    "    f\"treace_zipcode_surgeon_counts_{timestamp}.xlsx\"\n",
    ")\n",
    "\n",
    "out_df.to_excel(output_path, index=False)\n",
    "print(\"Saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee9a79-a6e2-4bf6-96bc-015c94384c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
